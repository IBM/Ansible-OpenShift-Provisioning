---

- name: Create CoreOS control nodes on the the KVM host.
  tags: create_control_nodes
  command: |
    virt-install \
    --name {{ env.cluster.nodes.control.vm_name[i] }} \
    --autostart \
    --disk pool={{ env.cluster.networking.metadata_name }}-vdisk,size={{ env.cluster.nodes.control.disk_size }}  \
    --ram {{env.cluster.nodes.control.ram}} \
    --cpu host \
    --vcpus {{env.cluster.nodes.control.vcpu}} \
    --network network={{env.bridge_name}} \
    --location /var/lib/libvirt/images,kernel=rhcos-live-kernel-{{ env.openshift.version }}-{{ env.install_config.control.architecture }},initrd=rhcos-live-initramfs-{{ env.openshift.version }}-{{ env.install_config.control.architecture }}.img \
    --extra-args "rd.neednet=1 coreos.inst=yes coreos.inst.install_dev=vda coreos.live.rootfs_url=http://{{env.bastion.networking.ip}}:8080/bin/rhcos-live-rootfs-{{ env.openshift.version }}-{{ env.install_config.control.architecture }}.img ip={{env.cluster.nodes.control.ip[i]}}::{{networking.gateway}}:{{networking.subnetmask}}:{{env.cluster.nodes.control.hostname[i]}}::none:1500 nameserver={{env.cluster.networking.nameserver1}} {{ ('--nameserver=' + env.cluster.networking.nameserver2) if env.cluster.networking.nameserver2 is defined else '' }} coreos.inst.ignition_url=http://{{env.bastion.networking.ip}}:8080/ignition/master.ign" \
    --graphics none \
    --wait=-1 \
    --noautoconsole
  with_sequence: start=0 end={{(env.cluster.nodes.control.hostname | length) - 1}} stride=1
  loop_control:
    extended: yes
    index_var: i
  when: env.z.high_availability == False and inventory_hostname == env.z.lpar1.hostname

- name: Create the first CoreOS control node on the first KVM host, if cluster is to be highly available.
  tags: create_control_nodes
  command: |
    virt-install \
    --name {{ env.cluster.nodes.control.vm_name[0] }} \
    --autostart \
    --disk pool={{ env.cluster.networking.metadata_name }}-vdisk,size={{ env.cluster.nodes.control.disk_size }}  \
    --ram {{env.cluster.nodes.control.ram}} \
    --cpu host \
    --vcpus {{env.cluster.nodes.control.vcpu}} \
    --network network={{env.bridge_name}} \
    --location /var/lib/libvirt/images,kernel=rhcos-live-kernel-{{ env.openshift.version }}-{{ env.install_config.control.architecture }},initrd=rhcos-live-initramfs-{{ env.openshift.version }}-{{ env.install_config.control.architecture }}.img \
    --extra-args "rd.neednet=1 coreos.inst=yes coreos.inst.install_dev=vda coreos.live.rootfs_url=http://{{env.bastion.networking.ip}}:8080/bin/rhcos-live-rootfs-{{ env.openshift.version }}-{{ env.install_config.control.architecture }}.img ip={{env.cluster.nodes.control.ip[0]}}::{{networking.gateway}}:{{networking.subnetmask}}:{{env.cluster.nodes.control.hostname[0]}}::none:1500 nameserver={{env.cluster.networking.nameserver1}} {{ ('--nameserver=' + env.cluster.networking.nameserver2) if env.cluster.networking.nameserver2 is defined else '' }} coreos.inst.ignition_url=http://{{env.bastion.networking.ip}}:8080/ignition/master.ign" \
    --graphics none \
    --wait=-1 \
    --noautoconsole
  when: env.z.high_availability == True and inventory_hostname == env.z.lpar1.hostname

- name: Create the second CoreOS control node on the second KVM host, if cluster is to be highly available.
  tags: create_control_nodes
  command: |
    virt-install \
    --name {{ env.cluster.nodes.control.vm_name[1] }} \
    --autostart \
    --disk pool={{ env.cluster.networking.metadata_name }}-vdisk,size={{ env.cluster.nodes.control.disk_size }}  \
    --ram {{env.cluster.nodes.control.ram}} \
    --cpu host \
    --vcpus {{env.cluster.nodes.control.vcpu}} \
    --network network={{env.bridge_name}} \
    --location /var/lib/libvirt/images,kernel=rhcos-live-kernel-{{ env.openshift.version }}-{{ env.install_config.control.architecture }},initrd=rhcos-live-initramfs-{{ env.openshift.version }}-{{ env.install_config.control.architecture }}.img \
    --extra-args "rd.neednet=1 coreos.inst=yes coreos.inst.install_dev=vda coreos.live.rootfs_url=http://{{env.bastion.networking.ip}}:8080/bin/rhcos-live-rootfs-{{ env.openshift.version }}-{{ env.install_config.control.architecture }}.img ip={{env.cluster.nodes.control.ip[1]}}::{{networking.gateway}}:{{networking.subnetmask}}:{{env.cluster.nodes.control.hostname[1]}}::none:1500 nameserver={{env.cluster.networking.nameserver1}} {{ ('--nameserver=' + env.cluster.networking.nameserver2) if env.cluster.networking.nameserver2 is defined else '' }} coreos.inst.ignition_url=http://{{env.bastion.networking.ip}}:8080/ignition/master.ign" \
    --graphics none \
    --wait=-1 \
    --noautoconsole
  when: env.z.high_availability == True and inventory_hostname == env.z.lpar2.hostname

- name: Create the third CoreOS control node on the third KVM host, if cluster is to be highly available.
  tags: create_control_nodes
  command: |
    virt-install \
    --name {{ env.cluster.nodes.control.vm_name[2] }} \
    --autostart \
    --disk pool={{ env.cluster.networking.metadata_name }}-vdisk,size={{ env.cluster.nodes.control.disk_size }}  \
    --ram {{env.cluster.nodes.control.ram}} \
    --cpu host \
    --vcpus {{env.cluster.nodes.control.vcpu}} \
    --network network={{env.bridge_name}} \
    --location /var/lib/libvirt/images,kernel=rhcos-live-kernel-{{ env.openshift.version }}-{{ env.install_config.control.architecture }},initrd=rhcos-live-initramfs-{{ env.openshift.version }}-{{ env.install_config.control.architecture }}.img \
    --extra-args "rd.neednet=1 coreos.inst=yes coreos.inst.install_dev=vda coreos.live.rootfs_url=http://{{env.bastion.networking.ip}}:8080/bin/rhcos-live-rootfs-{{ env.openshift.version }}-{{ env.install_config.control.architecture }}.img ip={{env.cluster.nodes.control.ip[2]}}::{{networking.gateway}}:{{networking.subnetmask}}:{{env.cluster.nodes.control.hostname[2]}}::none:1500 nameserver={{env.cluster.networking.nameserver1}} {{ ('--nameserver=' + env.cluster.networking.nameserver2) if env.cluster.networking.nameserver2 is defined else '' }} coreos.inst.ignition_url=http://{{env.bastion.networking.ip}}:8080/ignition/master.ign" \
    --graphics none \
    --wait=-1 \
    --noautoconsole
  when: env.z.high_availability == True and inventory_hostname == env.z.lpar3.hostname
